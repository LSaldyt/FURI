#!/usr/bin/env python3.5
import sys, pickle

# TensorFlow and tf.keras
import tensorflow as tf
from tensorflow import keras

# Helper libraries
import numpy as np
import matplotlib.pyplot as plt

import random

def unpair(paired):
    A = []
    B = []
    for a, b in paired:
        A.append(a)
        B.append(b)
    return A, B

maxbits = 256

to_binary_list  = lambda n : list(map(int, bin(n)[2:]))
pad_binary_list = lambda l : [0] * (maxbits - len(l)) + l
def binary(n):
    #print(n)
    return pad_binary_list(to_binary_list(n))

def run_nn_test(data, N, train_p, representation, randomize=True):
    print(len(data))
    if randomize:
        random.shuffle(data)

    if representation == 'binary':
        data = [(binary(n), label) for n, label in data]

    split = int(N*train_p)
    train_ns, train_labels = unpair(data[:split])
    test_ns, test_labels   = unpair(data[split:])

    train_ns = np.array(train_ns)
    train_labels = np.array(train_labels)
    test_ns  = np.array(test_ns)
    test_labels = np.array(test_labels)

    model = keras.Sequential([
        keras.layers.InputLayer(input_shape=((maxbits,) if representation == 'binary' else (1,))),
        keras.layers.Dense(128, activation=tf.nn.relu),
        keras.layers.Dense(128, activation=tf.nn.relu),
        keras.layers.Dense(2, activation=tf.nn.softmax)
    ])

    model.compile(optimizer=tf.train.AdamOptimizer(),
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])

    model.fit(train_ns, train_labels, epochs=5)

    print(test_ns)
    test_loss, test_acc = model.evaluate(test_ns, test_labels)
    print('Test accuracy:', test_acc)
    return model

def gen_evens(N, start=1):
    return [(2 * n, True) for n in range(start, N+1)]

def gen_odds(N, start=1):
    return [(2 * n + 1, False) for n in range(start, N+1)]

from sieve import gen_primes, gen_composites, take

def main(args):
    N = 10 ** 4
    train_p = 0.8
    predict_p = 0.8
    representation = 'binary'
    #representation = 'decimal'

    if len(args) > 0:
        filename = args[0]
        with open(filename, 'rb') as infile:
            data = pickle.load(infile)
        predict_data = data[int(predict_p * len(data)):]
        data         = data[:int(predict_p * len(data)) + 1]
        N = len(data)
    else:
        data = gen_evens(N) + gen_odds(N)
        #data = [(n, True) for n in take(gen_primes(), N)] + [(n, False) for n in take(gen_composites(), N)]
        predict_data = gen_evens(N*10, start=N) + gen_odds(N*10, start=N)
        #predict_data = [(n, True) for n in take(gen_primes(data[N][0]), N*10)] + [(n, True) for n in take(gen_composites(data[N + 1][0]), N*10)]
    if representation == 'binary':
        predict_data = [(binary(n), label) for n, label in predict_data]
    predict_ns, predict_labels = unpair(predict_data)
    predict_ns     = np.array(predict_ns)
    predict_labels = np.array(predict_labels)

    print('Learning split with {} datapoints and p={} training data'.format(N, train_p))

    model = run_nn_test(data, N, train_p, representation, randomize=True)
    extra_loss, extra_acc = model.evaluate(predict_ns, predict_labels)
    print('Accuracy from N={} to the next power of ten:'.format(N))
    print(extra_acc)

if __name__ == '__main__':
    sys.exit(main(sys.argv[1:]))
